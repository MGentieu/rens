import json
from elasticsearch import Elasticsearch, helpers
from dotenv import load_dotenv
import os


cloud_url = "https://a687f6d1571f4f6ab6f8c80b66f8af15.us-central1.gcp.cloud.es.io:443"  # ‚Üê ton URL cloud
index_name = "all_press_articles_flattened"
load_dotenv("../.env")
api_key = os.getenv("ELASTIC_SEARCH_API_KEY")

# --- Connexion Elasticsearch Cloud ---
es = Elasticsearch(
    cloud_url,
    api_key=api_key,
    verify_certs=True  # en production, toujours True
)

# --- V√©rifier la connexion ---
if es.ping():
    print("‚úÖ Connexion r√©ussie √† Elasticsearch Cloud")
else:
    print("‚ùå √âchec de la connexion au cluster")

# üîπ Cr√©er l'index (si il n'existe pas)
if not es.indices.exists(index=index_name):
    es.indices.create(index=index_name, mappings={
       "properties": {
            "id": {"type": "long"},
            "mark": {"type": "text"},
            "date": {"type": "date", "format": "epoch_second"},
            "title": {"type": "text"},
            "country": {"type": "keyword"},
            "sentiment": {"type": "float"}
        }
    }
)
    print(f"Index '{index_name}' created.")
else:
    print(f"Index '{index_name}' already exists.")

# üîπ Charger le fichier JSON
with open("../data/p3_bis_21k_articles_flattened.json", "r", encoding="utf-8") as f:
    articles = json.load(f)

# üîπ Pr√©parer les documents pour bulk insert
actions = []
for article in articles:
    actions.append({
        "_index": index_name,
        "_id": article["id"],  # optionnel : utiliser l'id existant comme _id
        "_source": article
    })

# üîπ Ins√©rer tous les documents en bulk
helpers.bulk(es, actions)
print(f"{len(actions)} articles indexed successfully into '{index_name}'.")
